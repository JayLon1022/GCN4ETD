{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba7871008ccd8e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T05:48:23.427760Z",
     "start_time": "2024-12-16T05:48:18.439498Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import scipy.sparse as sp\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, nfeat, nhid, nclass, dropout):\n",
    "        super(GCN, self).__init__()\n",
    "        self.gc1 = GraphConvolution(nfeat, nhid)  # 第一层图卷积\n",
    "        self.gc2 = GraphConvolution(nhid, nclass)  # 第二层图卷积\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        x = F.relu(self.gc1(x, adj))  # 图卷积 + ReLU\n",
    "        x = F.dropout(x, self.dropout, training=self.training)  # 防止过拟合\n",
    "        x = self.gc2(x, adj)  # 输出层\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "class GraphConvolution(nn.Module):\n",
    "    def __init__(self, in_features, out_features, bias=True):\n",
    "        super(GraphConvolution, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight = nn.Parameter(torch.FloatTensor(in_features, out_features))\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.FloatTensor(out_features))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        stdv = 1. / np.sqrt(self.weight.size(1))\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "        if self.bias is not None:\n",
    "            self.bias.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, input, adj):\n",
    "        support = torch.mm(input, self.weight)\n",
    "        output = torch.spmm(adj, support)\n",
    "        if self.bias is not None:\n",
    "            return output + self.bias\n",
    "        else:\n",
    "            return output\n",
    "\n",
    "dataset = pd.read_csv(\"UGR_sample_5M_balanced.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ebf32c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date time</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Source IP</th>\n",
       "      <th>Destination IP</th>\n",
       "      <th>Source Port</th>\n",
       "      <th>Destination Port</th>\n",
       "      <th>Protocol</th>\n",
       "      <th>Flag</th>\n",
       "      <th>Forwarding status</th>\n",
       "      <th>ToS</th>\n",
       "      <th>Packets</th>\n",
       "      <th>Bytes</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-07-27 13:43:29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>143.72.8.137</td>\n",
       "      <td>42.219.158.161</td>\n",
       "      <td>53</td>\n",
       "      <td>43192</td>\n",
       "      <td>UDP</td>\n",
       "      <td>.A....</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>214</td>\n",
       "      <td>background</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-07-27 13:43:29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.219.154.119</td>\n",
       "      <td>143.72.8.137</td>\n",
       "      <td>60185</td>\n",
       "      <td>53</td>\n",
       "      <td>UDP</td>\n",
       "      <td>.A....</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>background</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-07-27 13:43:30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.219.154.107</td>\n",
       "      <td>143.72.8.137</td>\n",
       "      <td>48598</td>\n",
       "      <td>53</td>\n",
       "      <td>UDP</td>\n",
       "      <td>.A....</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>77</td>\n",
       "      <td>background</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-07-27 13:43:30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.219.154.98</td>\n",
       "      <td>143.72.8.137</td>\n",
       "      <td>51465</td>\n",
       "      <td>53</td>\n",
       "      <td>UDP</td>\n",
       "      <td>.A....</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>background</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-07-27 13:43:30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.164.49.177</td>\n",
       "      <td>42.219.155.26</td>\n",
       "      <td>80</td>\n",
       "      <td>37934</td>\n",
       "      <td>TCP</td>\n",
       "      <td>.A...F</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>background</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date time  Duration       Source IP  Destination IP  Source Port  \\\n",
       "0  2016-07-27 13:43:29       0.0    143.72.8.137  42.219.158.161           53   \n",
       "1  2016-07-27 13:43:29       0.0  42.219.154.119    143.72.8.137        60185   \n",
       "2  2016-07-27 13:43:30       0.0  42.219.154.107    143.72.8.137        48598   \n",
       "3  2016-07-27 13:43:30       0.0   42.219.154.98    143.72.8.137        51465   \n",
       "4  2016-07-27 13:43:30       0.0   43.164.49.177   42.219.155.26           80   \n",
       "\n",
       "   Destination Port Protocol    Flag  Forwarding status  ToS  Packets  Bytes  \\\n",
       "0             43192      UDP  .A....                  0    0        1    214   \n",
       "1                53      UDP  .A....                  0    0        1     72   \n",
       "2                53      UDP  .A....                  0    0        1     77   \n",
       "3                53      UDP  .A....                  0    0        1     63   \n",
       "4             37934      TCP  .A...F                  0    0        1     52   \n",
       "\n",
       "        Label  \n",
       "0  background  \n",
       "1  background  \n",
       "2  background  \n",
       "3  background  \n",
       "4  background  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f5a77cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据集类别分布：\n",
      "Label\n",
      "background      4931787\n",
      "dos               27419\n",
      "blacklist         13770\n",
      "scan44            13025\n",
      "nerisbotnet        6234\n",
      "anomaly-spam       4961\n",
      "scan11             2804\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X = dataset.drop(columns=['Label'])\n",
    "y = dataset['Label']\n",
    "\n",
    "train_data = pd.DataFrame(X, columns=X.columns)\n",
    "train_data['Label'] = y\n",
    "\n",
    "# 查看数据集类别分布\n",
    "print(\"数据集类别分布：\")\n",
    "print(train_data['Label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6497d336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "background      5000\n",
      "dos             2015\n",
      "blacklist       1045\n",
      "scan44           957\n",
      "nerisbotnet      428\n",
      "anomaly-spam     355\n",
      "scan11           200\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "major_data = dataset[dataset['Label'] == \"background\"]\n",
    "major_data = major_data.sample(n=10000, random_state=42)\n",
    "minor_data = dataset[dataset['Label'] != \"background\"]\n",
    "minor_data = minor_data.sample(n=10000, random_state=42)\n",
    "data = pd.concat([major_data, minor_data], ignore_index=True)\n",
    "data = data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# print(data.head())\n",
    "print(data['Label'].value_counts())\n",
    "# print(data['Source IP'].value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fc679507",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_graph(data):\n",
    "    \"\"\"\n",
    "    构建图结构，包括节点特征矩阵和邻接矩阵\n",
    "    \"\"\"\n",
    "    # 提取特征\n",
    "    features_columns = ['Duration', 'Source Port', 'Destination Port', 'Packets', 'Bytes']\n",
    "    features = data[features_columns]\n",
    "\n",
    "    # 转换 IP 地址为数值\n",
    "    data['Source IP'] = data['Source IP'].apply(lambda x: int(''.join(x.split('.'))))\n",
    "    data['Destination IP'] = data['Destination IP'].apply(lambda x: int(''.join(x.split('.'))))\n",
    "\n",
    "    # 归一化特征\n",
    "    scaler = MinMaxScaler()\n",
    "    features = scaler.fit_transform(features)\n",
    "\n",
    "    # 使用哈希表加速构图\n",
    "    ip_to_indices = {}\n",
    "    for idx, ip in enumerate(data['Source IP']):\n",
    "        if ip not in ip_to_indices:\n",
    "            ip_to_indices[ip] = []\n",
    "        ip_to_indices[ip].append(idx)\n",
    "\n",
    "    adj_list = []\n",
    "    for idx, dst_ip in enumerate(data['Destination IP']):\n",
    "        if dst_ip in ip_to_indices:\n",
    "            for neighbor_idx in ip_to_indices[dst_ip]:\n",
    "                adj_list.append((idx, neighbor_idx))\n",
    "\n",
    "    # 构造邻接矩阵\n",
    "    rows, cols = zip(*adj_list)\n",
    "    adj = sp.coo_matrix(\n",
    "        (np.ones(len(rows)), (rows, cols)),\n",
    "        shape=(len(data), len(data)),\n",
    "        dtype=np.float32\n",
    "    )\n",
    "\n",
    "    return torch.FloatTensor(features), sparse_mx_to_torch_sparse_tensor(adj)\n",
    "\n",
    "\n",
    "# 稀疏矩阵转 PyTorch 稀疏张量\n",
    "def sparse_mx_to_torch_sparse_tensor(sparse_mx):\n",
    "    \"\"\"Convert a scipy sparse matrix to torch sparse tensor.\"\"\"\n",
    "    sparse_mx = sparse_mx.tocoo().astype(np.float32)\n",
    "    indices = torch.from_numpy(np.vstack((sparse_mx.row, sparse_mx.col)).astype(np.int64))\n",
    "    values = torch.from_numpy(sparse_mx.data)\n",
    "    shape = torch.Size(sparse_mx.shape)\n",
    "    return torch.sparse.FloatTensor(indices, values, shape)\n",
    "\n",
    "features, adj = build_graph(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c0644251",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Label'] = data['Label'].apply(lambda x: 0 if x == 'background' else 1)\n",
    "labels = data['Label']\n",
    "labels = torch.LongTensor(labels.values)\n",
    "\n",
    "# 将数据移动到 GPU\n",
    "features = features.to(device)\n",
    "adj = adj.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "49acce19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "1    5000\n",
      "0    5000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data['Label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "388cbf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分训练集、验证集和测试集\n",
    "idx_train, idx_temp, labels_train, labels_temp = train_test_split(\n",
    "    range(len(labels)), labels, test_size=0.4, stratify=labels, random_state=42\n",
    ")\n",
    "idx_val, idx_test, labels_val, labels_test = train_test_split(\n",
    "    idx_temp, labels_temp, test_size=0.5, stratify=labels_temp, random_state=42\n",
    ")\n",
    "\n",
    "labels = labels.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b50afac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1], device='cuda:0')\n",
      "tensor([0, 1], device='cuda:0')\n",
      "tensor([0, 1], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(labels[idx_test].unique())\n",
    "print(labels[idx_train].unique())\n",
    "print(labels[idx_val].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3903ce93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx_train = torch.LongTensor(idx_train)\n",
    "# idx_val = torch.LongTensor(idx_val)\n",
    "# idx_test = torch.LongTensor(idx_test)\n",
    "\n",
    "idx_train = torch.LongTensor(idx_train).to(device)\n",
    "idx_val = torch.LongTensor(idx_val).to(device)\n",
    "idx_test = torch.LongTensor(idx_test).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8889cd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gcn(adj, features, labels, idx_train, idx_val, nfeat, nhid, nclass, epochs=200, lr=0.01, weight_decay=5e-4, dropout=0.5):\n",
    "    # 初始化模型和优化器\n",
    "    # model = GCN(nfeat=nfeat, nhid=nhid, nclass=nclass, dropout=dropout)\n",
    "    model = GCN(nfeat=nfeat, nhid=nhid, nclass=nclass, dropout=dropout).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    # 训练模型\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(features, adj)  # 前向传播\n",
    "        loss_train = F.nll_loss(output[idx_train], labels[idx_train])  # 计算损失\n",
    "        loss_train.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # 验证集评估\n",
    "        model.eval()\n",
    "        output = model(features, adj)\n",
    "        loss_val = F.nll_loss(output[idx_val], labels[idx_val])\n",
    "        acc_val = accuracy(output[idx_val], labels[idx_val])\n",
    "        print(f\"Epoch {epoch+1}: Train Loss = {loss_train.item():.4f}, Val Loss = {loss_val.item():.4f}, Val Accuracy = {acc_val:.4f}\")\n",
    "    return model\n",
    "\n",
    "def accuracy(output, labels):\n",
    "    \"\"\"计算分类准确率\"\"\"\n",
    "    preds = output.max(1)[1].type_as(labels)\n",
    "    correct = preds.eq(labels).double()\n",
    "    correct = correct.sum()\n",
    "    return correct / len(labels)\n",
    "\n",
    "def evaluate_gcn(model, adj, features, labels, idx_test):\n",
    "    from tabulate import tabulate\n",
    "    \"\"\"评估模型\"\"\"\n",
    "    model.eval()\n",
    "    output = model(features, adj)\n",
    "    preds = output[idx_test].max(1)[1].type_as(labels)\n",
    "    \n",
    "    # 获取分类报告\n",
    "    report = classification_report(labels[idx_test].cpu().numpy(), preds.cpu().numpy(), output_dict=True)\n",
    "    \n",
    "    # 格式化并打印分类报告\n",
    "    print(\"Test Classification Report:\")\n",
    "    print(tabulate(\n",
    "        [[key] + [f\"{value:.2f}\" for value in metrics.values()] for key, metrics in report.items() if isinstance(metrics, dict)],\n",
    "        headers=[\"Class\", \"Precision\", \"Recall\", \"F1-Score\", \"Support\"],\n",
    "        tablefmt=\"grid\"\n",
    "    ))\n",
    "\n",
    "    # 打印 accuracy, macro avg, weighted avg\n",
    "    accuracy = report['accuracy']\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "96b573de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 312.8475, Val Loss = 218.7255, Val Accuracy = 0.7295\n",
      "Epoch 2: Train Loss = 272.3918, Val Loss = 181.9314, Val Accuracy = 0.7845\n",
      "Epoch 3: Train Loss = 226.2786, Val Loss = 145.8314, Val Accuracy = 0.7845\n",
      "Epoch 4: Train Loss = 180.8818, Val Loss = 110.6456, Val Accuracy = 0.7695\n",
      "Epoch 5: Train Loss = 136.5224, Val Loss = 336.0614, Val Accuracy = 0.5905\n",
      "Epoch 6: Train Loss = 347.6242, Val Loss = 81.1807, Val Accuracy = 0.7955\n",
      "Epoch 7: Train Loss = 100.0411, Val Loss = 76.2767, Val Accuracy = 0.8020\n",
      "Epoch 8: Train Loss = 94.1534, Val Loss = 69.1644, Val Accuracy = 0.8025\n",
      "Epoch 9: Train Loss = 85.4900, Val Loss = 60.0418, Val Accuracy = 0.8045\n",
      "Epoch 10: Train Loss = 74.3001, Val Loss = 49.2769, Val Accuracy = 0.8060\n",
      "Epoch 11: Train Loss = 61.0431, Val Loss = 37.0403, Val Accuracy = 0.8080\n",
      "Epoch 12: Train Loss = 45.9407, Val Loss = 23.3707, Val Accuracy = 0.8180\n",
      "Epoch 13: Train Loss = 29.0655, Val Loss = 8.5797, Val Accuracy = 0.8145\n",
      "Epoch 14: Train Loss = 10.7645, Val Loss = 112.4754, Val Accuracy = 0.7090\n",
      "Epoch 15: Train Loss = 110.1806, Val Loss = 59.4067, Val Accuracy = 0.7090\n",
      "Epoch 16: Train Loss = 58.2870, Val Loss = 9.8365, Val Accuracy = 0.8165\n",
      "Epoch 17: Train Loss = 12.4576, Val Loss = 19.4432, Val Accuracy = 0.8210\n",
      "Epoch 18: Train Loss = 24.4399, Val Loss = 27.0704, Val Accuracy = 0.8205\n",
      "Epoch 19: Train Loss = 33.9268, Val Loss = 32.7581, Val Accuracy = 0.8150\n",
      "Epoch 20: Train Loss = 41.0062, Val Loss = 36.7241, Val Accuracy = 0.8110\n",
      "Epoch 21: Train Loss = 45.9388, Val Loss = 38.5300, Val Accuracy = 0.8125\n",
      "Epoch 22: Train Loss = 48.1235, Val Loss = 37.7569, Val Accuracy = 0.8180\n",
      "Epoch 23: Train Loss = 47.0078, Val Loss = 34.3998, Val Accuracy = 0.8200\n",
      "Epoch 24: Train Loss = 42.7235, Val Loss = 29.0778, Val Accuracy = 0.8230\n",
      "Epoch 25: Train Loss = 36.0130, Val Loss = 22.0180, Val Accuracy = 0.8265\n",
      "Epoch 26: Train Loss = 27.1350, Val Loss = 13.4519, Val Accuracy = 0.8395\n",
      "Epoch 27: Train Loss = 16.3545, Val Loss = 3.6706, Val Accuracy = 0.8255\n",
      "Epoch 28: Train Loss = 3.9700, Val Loss = 16.5484, Val Accuracy = 0.8065\n",
      "Epoch 29: Train Loss = 14.2557, Val Loss = 166.1019, Val Accuracy = 0.5000\n",
      "Epoch 30: Train Loss = 159.9038, Val Loss = 2.9737, Val Accuracy = 0.8145\n",
      "Epoch 31: Train Loss = 3.1074, Val Loss = 17.1988, Val Accuracy = 0.8290\n",
      "Epoch 32: Train Loss = 21.1522, Val Loss = 29.6806, Val Accuracy = 0.8230\n",
      "Epoch 33: Train Loss = 36.8540, Val Loss = 40.0983, Val Accuracy = 0.8180\n",
      "Epoch 34: Train Loss = 49.9685, Val Loss = 48.6402, Val Accuracy = 0.8115\n",
      "Epoch 35: Train Loss = 60.7328, Val Loss = 55.4640, Val Accuracy = 0.8080\n",
      "Epoch 36: Train Loss = 69.3462, Val Loss = 60.6889, Val Accuracy = 0.8065\n",
      "Epoch 37: Train Loss = 75.9600, Val Loss = 64.4738, Val Accuracy = 0.8070\n",
      "Epoch 38: Train Loss = 80.7697, Val Loss = 66.9694, Val Accuracy = 0.8070\n",
      "Epoch 39: Train Loss = 83.9659, Val Loss = 68.2916, Val Accuracy = 0.8070\n",
      "Epoch 40: Train Loss = 85.6935, Val Loss = 68.5365, Val Accuracy = 0.8070\n",
      "Epoch 41: Train Loss = 86.0726, Val Loss = 67.8201, Val Accuracy = 0.8080\n",
      "Epoch 42: Train Loss = 85.2490, Val Loss = 66.2201, Val Accuracy = 0.8100\n",
      "Epoch 43: Train Loss = 83.3195, Val Loss = 63.7996, Val Accuracy = 0.8100\n",
      "Epoch 44: Train Loss = 80.3626, Val Loss = 60.6289, Val Accuracy = 0.8150\n",
      "Epoch 45: Train Loss = 76.4663, Val Loss = 56.7720, Val Accuracy = 0.8155\n",
      "Epoch 46: Train Loss = 71.7101, Val Loss = 52.2858, Val Accuracy = 0.8180\n",
      "Epoch 47: Train Loss = 66.1655, Val Loss = 47.2225, Val Accuracy = 0.8185\n",
      "Epoch 48: Train Loss = 59.8979, Val Loss = 41.6417, Val Accuracy = 0.8105\n",
      "Epoch 49: Train Loss = 52.9785, Val Loss = 35.6847, Val Accuracy = 0.8075\n",
      "Epoch 50: Train Loss = 45.5580, Val Loss = 29.3171, Val Accuracy = 0.8150\n",
      "Epoch 51: Train Loss = 37.6176, Val Loss = 27.3199, Val Accuracy = 0.8290\n",
      "Epoch 52: Train Loss = 33.4140, Val Loss = 42.0336, Val Accuracy = 0.7500\n",
      "Epoch 53: Train Loss = 45.1106, Val Loss = 36.6347, Val Accuracy = 0.7835\n",
      "Epoch 54: Train Loss = 39.8719, Val Loss = 22.7127, Val Accuracy = 0.8235\n",
      "Epoch 55: Train Loss = 28.4738, Val Loss = 24.2604, Val Accuracy = 0.8220\n",
      "Epoch 56: Train Loss = 31.0346, Val Loss = 26.6878, Val Accuracy = 0.8135\n",
      "Epoch 57: Train Loss = 33.9688, Val Loss = 27.9146, Val Accuracy = 0.8115\n",
      "Epoch 58: Train Loss = 35.4067, Val Loss = 28.1309, Val Accuracy = 0.8115\n",
      "Epoch 59: Train Loss = 35.5941, Val Loss = 27.3771, Val Accuracy = 0.8115\n",
      "Epoch 60: Train Loss = 34.5817, Val Loss = 25.5784, Val Accuracy = 0.8125\n",
      "Epoch 61: Train Loss = 32.2635, Val Loss = 22.8232, Val Accuracy = 0.8140\n",
      "Epoch 62: Train Loss = 28.7488, Val Loss = 19.1939, Val Accuracy = 0.8170\n",
      "Epoch 63: Train Loss = 24.1398, Val Loss = 14.8485, Val Accuracy = 0.8200\n",
      "Epoch 64: Train Loss = 18.6387, Val Loss = 10.0954, Val Accuracy = 0.8430\n",
      "Epoch 65: Train Loss = 12.6375, Val Loss = 17.3236, Val Accuracy = 0.7500\n",
      "Epoch 66: Train Loss = 18.3079, Val Loss = 7.0056, Val Accuracy = 0.7870\n",
      "Epoch 67: Train Loss = 8.2122, Val Loss = 7.9128, Val Accuracy = 0.8285\n",
      "Epoch 68: Train Loss = 9.6394, Val Loss = 10.3004, Val Accuracy = 0.8210\n",
      "Epoch 69: Train Loss = 12.5350, Val Loss = 11.3376, Val Accuracy = 0.8195\n",
      "Epoch 70: Train Loss = 13.7425, Val Loss = 11.1143, Val Accuracy = 0.8200\n",
      "Epoch 71: Train Loss = 13.3733, Val Loss = 9.7317, Val Accuracy = 0.8210\n",
      "Epoch 72: Train Loss = 11.5541, Val Loss = 7.2889, Val Accuracy = 0.8170\n",
      "Epoch 73: Train Loss = 8.4084, Val Loss = 3.8881, Val Accuracy = 0.8165\n",
      "Epoch 74: Train Loss = 4.0741, Val Loss = 8.5813, Val Accuracy = 0.8080\n",
      "Epoch 75: Train Loss = 7.7579, Val Loss = 12.1202, Val Accuracy = 0.8190\n",
      "Epoch 76: Train Loss = 10.5828, Val Loss = 14.8375, Val Accuracy = 0.8090\n",
      "Epoch 77: Train Loss = 12.8967, Val Loss = 15.9054, Val Accuracy = 0.8090\n",
      "Epoch 78: Train Loss = 13.8060, Val Loss = 15.4569, Val Accuracy = 0.8020\n",
      "Epoch 79: Train Loss = 13.4206, Val Loss = 13.8026, Val Accuracy = 0.8170\n",
      "Epoch 80: Train Loss = 12.0487, Val Loss = 11.7928, Val Accuracy = 0.8150\n",
      "Epoch 81: Train Loss = 10.4961, Val Loss = 9.1536, Val Accuracy = 0.8145\n",
      "Epoch 82: Train Loss = 8.4415, Val Loss = 5.9448, Val Accuracy = 0.8140\n",
      "Epoch 83: Train Loss = 5.9327, Val Loss = 6.9608, Val Accuracy = 0.8170\n",
      "Epoch 84: Train Loss = 7.7904, Val Loss = 8.8667, Val Accuracy = 0.8180\n",
      "Epoch 85: Train Loss = 10.2003, Val Loss = 9.4670, Val Accuracy = 0.8260\n",
      "Epoch 86: Train Loss = 10.9719, Val Loss = 8.8681, Val Accuracy = 0.8195\n",
      "Epoch 87: Train Loss = 10.2410, Val Loss = 7.1935, Val Accuracy = 0.8185\n",
      "Epoch 88: Train Loss = 8.1604, Val Loss = 4.5609, Val Accuracy = 0.8255\n",
      "Epoch 89: Train Loss = 4.8804, Val Loss = 7.0438, Val Accuracy = 0.8165\n",
      "Epoch 90: Train Loss = 6.5447, Val Loss = 9.3259, Val Accuracy = 0.8175\n",
      "Epoch 91: Train Loss = 8.2700, Val Loss = 10.5527, Val Accuracy = 0.8095\n",
      "Epoch 92: Train Loss = 9.1748, Val Loss = 10.8256, Val Accuracy = 0.8155\n",
      "Epoch 93: Train Loss = 9.4031, Val Loss = 9.5424, Val Accuracy = 0.8150\n",
      "Epoch 94: Train Loss = 8.3014, Val Loss = 7.2183, Val Accuracy = 0.8280\n",
      "Epoch 95: Train Loss = 6.4007, Val Loss = 4.3622, Val Accuracy = 0.8095\n",
      "Epoch 96: Train Loss = 4.1150, Val Loss = 4.1777, Val Accuracy = 0.8185\n",
      "Epoch 97: Train Loss = 4.6490, Val Loss = 5.5420, Val Accuracy = 0.8190\n",
      "Epoch 98: Train Loss = 6.3964, Val Loss = 5.5976, Val Accuracy = 0.8190\n",
      "Epoch 99: Train Loss = 6.5022, Val Loss = 4.4680, Val Accuracy = 0.8200\n",
      "Epoch 100: Train Loss = 5.1197, Val Loss = 2.2790, Val Accuracy = 0.8330\n",
      "Epoch 101: Train Loss = 2.4124, Val Loss = 4.5995, Val Accuracy = 0.8205\n",
      "Epoch 102: Train Loss = 4.0913, Val Loss = 9.0149, Val Accuracy = 0.7570\n",
      "Epoch 103: Train Loss = 8.1455, Val Loss = 2.3121, Val Accuracy = 0.8330\n",
      "Epoch 104: Train Loss = 2.4702, Val Loss = 5.5422, Val Accuracy = 0.8205\n",
      "Epoch 105: Train Loss = 6.4767, Val Loss = 7.3019, Val Accuracy = 0.8210\n",
      "Epoch 106: Train Loss = 8.6499, Val Loss = 7.7058, Val Accuracy = 0.8195\n",
      "Epoch 107: Train Loss = 9.1267, Val Loss = 6.8763, Val Accuracy = 0.8205\n",
      "Epoch 108: Train Loss = 8.0609, Val Loss = 4.9323, Val Accuracy = 0.8200\n",
      "Epoch 109: Train Loss = 5.6007, Val Loss = 3.4642, Val Accuracy = 0.8095\n",
      "Epoch 110: Train Loss = 3.3860, Val Loss = 5.5846, Val Accuracy = 0.8270\n",
      "Epoch 111: Train Loss = 5.0506, Val Loss = 6.6078, Val Accuracy = 0.8320\n",
      "Epoch 112: Train Loss = 5.8491, Val Loss = 6.6112, Val Accuracy = 0.8320\n",
      "Epoch 113: Train Loss = 5.8398, Val Loss = 5.6866, Val Accuracy = 0.8295\n",
      "Epoch 114: Train Loss = 5.0945, Val Loss = 3.9406, Val Accuracy = 0.8165\n",
      "Epoch 115: Train Loss = 3.6999, Val Loss = 3.2234, Val Accuracy = 0.8210\n",
      "Epoch 116: Train Loss = 3.5018, Val Loss = 3.8584, Val Accuracy = 0.8210\n",
      "Epoch 117: Train Loss = 4.3209, Val Loss = 3.2064, Val Accuracy = 0.8210\n",
      "Epoch 118: Train Loss = 3.5288, Val Loss = 2.5128, Val Accuracy = 0.8225\n",
      "Epoch 119: Train Loss = 2.4134, Val Loss = 3.0856, Val Accuracy = 0.8320\n",
      "Epoch 120: Train Loss = 2.8242, Val Loss = 2.6381, Val Accuracy = 0.8330\n",
      "Epoch 121: Train Loss = 2.4293, Val Loss = 1.5747, Val Accuracy = 0.8425\n",
      "Epoch 122: Train Loss = 1.6100, Val Loss = 1.2868, Val Accuracy = 0.8330\n",
      "Epoch 123: Train Loss = 1.2776, Val Loss = 1.3937, Val Accuracy = 0.8365\n",
      "Epoch 124: Train Loss = 1.3218, Val Loss = 1.3437, Val Accuracy = 0.8540\n",
      "Epoch 125: Train Loss = 1.4249, Val Loss = 1.0209, Val Accuracy = 0.8565\n",
      "Epoch 126: Train Loss = 0.9870, Val Loss = 1.3588, Val Accuracy = 0.8690\n",
      "Epoch 127: Train Loss = 1.4802, Val Loss = 3.0022, Val Accuracy = 0.8085\n",
      "Epoch 128: Train Loss = 2.7670, Val Loss = 1.7702, Val Accuracy = 0.8625\n",
      "Epoch 129: Train Loss = 2.0095, Val Loss = 1.5959, Val Accuracy = 0.8570\n",
      "Epoch 130: Train Loss = 1.7784, Val Loss = 1.5117, Val Accuracy = 0.8415\n",
      "Epoch 131: Train Loss = 1.4047, Val Loss = 1.2558, Val Accuracy = 0.8510\n",
      "Epoch 132: Train Loss = 1.1798, Val Loss = 1.7869, Val Accuracy = 0.8460\n",
      "Epoch 133: Train Loss = 1.9863, Val Loss = 1.7058, Val Accuracy = 0.8460\n",
      "Epoch 134: Train Loss = 1.8759, Val Loss = 1.6306, Val Accuracy = 0.8460\n",
      "Epoch 135: Train Loss = 1.4979, Val Loss = 1.8461, Val Accuracy = 0.8455\n",
      "Epoch 136: Train Loss = 1.6751, Val Loss = 1.1313, Val Accuracy = 0.8480\n",
      "Epoch 137: Train Loss = 1.1524, Val Loss = 1.2878, Val Accuracy = 0.8440\n",
      "Epoch 138: Train Loss = 1.2143, Val Loss = 1.2903, Val Accuracy = 0.8475\n",
      "Epoch 139: Train Loss = 1.3619, Val Loss = 1.2448, Val Accuracy = 0.8455\n",
      "Epoch 140: Train Loss = 1.1711, Val Loss = 1.0750, Val Accuracy = 0.8555\n",
      "Epoch 141: Train Loss = 1.1050, Val Loss = 1.5185, Val Accuracy = 0.8575\n",
      "Epoch 142: Train Loss = 1.3893, Val Loss = 0.9618, Val Accuracy = 0.8575\n",
      "Epoch 143: Train Loss = 0.9254, Val Loss = 1.9803, Val Accuracy = 0.8560\n",
      "Epoch 144: Train Loss = 2.2779, Val Loss = 2.0455, Val Accuracy = 0.8555\n",
      "Epoch 145: Train Loss = 2.3699, Val Loss = 1.1587, Val Accuracy = 0.8710\n",
      "Epoch 146: Train Loss = 1.2347, Val Loss = 3.6636, Val Accuracy = 0.7975\n",
      "Epoch 147: Train Loss = 3.2223, Val Loss = 2.7744, Val Accuracy = 0.8445\n",
      "Epoch 148: Train Loss = 3.2366, Val Loss = 4.0986, Val Accuracy = 0.8335\n",
      "Epoch 149: Train Loss = 4.8452, Val Loss = 4.0062, Val Accuracy = 0.8330\n",
      "Epoch 150: Train Loss = 4.6922, Val Loss = 2.5820, Val Accuracy = 0.8350\n",
      "Epoch 151: Train Loss = 2.8799, Val Loss = 3.1944, Val Accuracy = 0.8340\n",
      "Epoch 152: Train Loss = 2.8558, Val Loss = 4.9791, Val Accuracy = 0.8370\n",
      "Epoch 153: Train Loss = 4.3034, Val Loss = 5.4702, Val Accuracy = 0.8370\n",
      "Epoch 154: Train Loss = 4.7068, Val Loss = 4.7743, Val Accuracy = 0.8355\n",
      "Epoch 155: Train Loss = 4.1504, Val Loss = 3.0320, Val Accuracy = 0.8325\n",
      "Epoch 156: Train Loss = 2.7516, Val Loss = 2.6336, Val Accuracy = 0.8340\n",
      "Epoch 157: Train Loss = 2.9087, Val Loss = 3.3429, Val Accuracy = 0.8290\n",
      "Epoch 158: Train Loss = 3.8091, Val Loss = 2.6100, Val Accuracy = 0.8345\n",
      "Epoch 159: Train Loss = 2.9066, Val Loss = 2.1465, Val Accuracy = 0.8340\n",
      "Epoch 160: Train Loss = 1.9821, Val Loss = 2.8993, Val Accuracy = 0.8370\n",
      "Epoch 161: Train Loss = 2.5629, Val Loss = 2.4421, Val Accuracy = 0.8380\n",
      "Epoch 162: Train Loss = 2.1714, Val Loss = 1.0995, Val Accuracy = 0.8475\n",
      "Epoch 163: Train Loss = 1.1156, Val Loss = 0.8995, Val Accuracy = 0.8450\n",
      "Epoch 164: Train Loss = 0.8840, Val Loss = 0.9750, Val Accuracy = 0.8565\n",
      "Epoch 165: Train Loss = 0.9282, Val Loss = 1.4821, Val Accuracy = 0.8560\n",
      "Epoch 166: Train Loss = 1.6665, Val Loss = 1.1972, Val Accuracy = 0.8715\n",
      "Epoch 167: Train Loss = 1.3119, Val Loss = 4.4918, Val Accuracy = 0.8020\n",
      "Epoch 168: Train Loss = 3.9143, Val Loss = 3.0755, Val Accuracy = 0.8460\n",
      "Epoch 169: Train Loss = 3.6713, Val Loss = 4.5657, Val Accuracy = 0.8350\n",
      "Epoch 170: Train Loss = 5.5042, Val Loss = 4.5651, Val Accuracy = 0.8360\n",
      "Epoch 171: Train Loss = 5.4775, Val Loss = 3.1665, Val Accuracy = 0.8360\n",
      "Epoch 172: Train Loss = 3.7100, Val Loss = 1.4532, Val Accuracy = 0.8370\n",
      "Epoch 173: Train Loss = 1.3517, Val Loss = 3.1804, Val Accuracy = 0.8565\n",
      "Epoch 174: Train Loss = 2.7639, Val Loss = 3.3697, Val Accuracy = 0.8565\n",
      "Epoch 175: Train Loss = 2.9206, Val Loss = 2.1339, Val Accuracy = 0.8380\n",
      "Epoch 176: Train Loss = 1.9075, Val Loss = 1.9557, Val Accuracy = 0.8445\n",
      "Epoch 177: Train Loss = 2.1836, Val Loss = 2.3294, Val Accuracy = 0.8440\n",
      "Epoch 178: Train Loss = 2.6589, Val Loss = 1.3428, Val Accuracy = 0.8475\n",
      "Epoch 179: Train Loss = 1.4372, Val Loss = 3.3466, Val Accuracy = 0.8180\n",
      "Epoch 180: Train Loss = 2.8973, Val Loss = 1.3887, Val Accuracy = 0.8375\n",
      "Epoch 181: Train Loss = 1.3030, Val Loss = 3.0580, Val Accuracy = 0.8350\n",
      "Epoch 182: Train Loss = 3.5344, Val Loss = 3.8508, Val Accuracy = 0.8320\n",
      "Epoch 183: Train Loss = 4.5092, Val Loss = 3.1189, Val Accuracy = 0.8345\n",
      "Epoch 184: Train Loss = 3.5814, Val Loss = 1.5496, Val Accuracy = 0.8325\n",
      "Epoch 185: Train Loss = 1.4950, Val Loss = 2.5582, Val Accuracy = 0.8355\n",
      "Epoch 186: Train Loss = 2.3012, Val Loss = 2.2770, Val Accuracy = 0.8350\n",
      "Epoch 187: Train Loss = 2.0687, Val Loss = 1.4832, Val Accuracy = 0.8440\n",
      "Epoch 188: Train Loss = 1.5561, Val Loss = 1.1541, Val Accuracy = 0.8460\n",
      "Epoch 189: Train Loss = 1.1584, Val Loss = 2.4794, Val Accuracy = 0.8380\n",
      "Epoch 190: Train Loss = 2.1888, Val Loss = 2.5390, Val Accuracy = 0.8485\n",
      "Epoch 191: Train Loss = 2.2264, Val Loss = 1.1734, Val Accuracy = 0.8380\n",
      "Epoch 192: Train Loss = 1.0983, Val Loss = 2.4562, Val Accuracy = 0.8465\n",
      "Epoch 193: Train Loss = 2.8696, Val Loss = 2.8042, Val Accuracy = 0.8470\n",
      "Epoch 194: Train Loss = 3.3299, Val Loss = 1.7856, Val Accuracy = 0.8570\n",
      "Epoch 195: Train Loss = 2.0790, Val Loss = 5.6918, Val Accuracy = 0.8030\n",
      "Epoch 196: Train Loss = 4.9072, Val Loss = 1.7383, Val Accuracy = 0.8565\n",
      "Epoch 197: Train Loss = 2.0153, Val Loss = 2.3878, Val Accuracy = 0.8470\n",
      "Epoch 198: Train Loss = 2.8027, Val Loss = 1.6316, Val Accuracy = 0.8490\n",
      "Epoch 199: Train Loss = 1.8372, Val Loss = 2.3543, Val Accuracy = 0.8585\n",
      "Epoch 200: Train Loss = 2.0633, Val Loss = 3.4326, Val Accuracy = 0.8180\n"
     ]
    }
   ],
   "source": [
    "model = train_gcn(adj, features, labels, idx_train, idx_val, nfeat=features.shape[1], nhid=16, nclass=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b9a63181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Classification Report:\n",
      "+--------------+-------------+----------+------------+-----------+\n",
      "| Class        |   Precision |   Recall |   F1-Score |   Support |\n",
      "+==============+=============+==========+============+===========+\n",
      "| 0            |        0.77 |     0.96 |       0.85 |      1000 |\n",
      "+--------------+-------------+----------+------------+-----------+\n",
      "| 1            |        0.94 |     0.71 |       0.81 |      1000 |\n",
      "+--------------+-------------+----------+------------+-----------+\n",
      "| macro avg    |        0.85 |     0.83 |       0.83 |      2000 |\n",
      "+--------------+-------------+----------+------------+-----------+\n",
      "| weighted avg |        0.85 |     0.83 |       0.83 |      2000 |\n",
      "+--------------+-------------+----------+------------+-----------+\n",
      "Accuracy: 0.8320\n"
     ]
    }
   ],
   "source": [
    "evaluate_gcn(model, adj, features, labels, idx_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mixmatch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
